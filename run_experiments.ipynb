{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import loadmat\n",
    "import pickle\n",
    "from scipy.signal import detrend\n",
    "\n",
    "data_df = pickle.load(open('data/vals_preproc.pkl', 'rb'))\n",
    "data_df_denoised = pickle.load(open('data/vals_denoised.pkl', 'rb'))\n",
    "data_df['scans'] = data_df['scans'].apply(lambda x: np.array(x).T)\n",
    "data_df['scans_0mean'] = data_df['scans_0mean'].apply(lambda x: np.array(x).T)\n",
    "                                                      \n",
    "data_df_denoised['scans'] = data_df_denoised['scans'].apply(lambda x: np.array(x).T)\n",
    "data_df_denoised['scans_0mean'] = data_df_denoised['scans_0mean'].apply(lambda x: np.array(x).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mvmd.mvmd import mvmd\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "from tqdm import tqdm\n",
    "Ks = range(6, 13)  \n",
    "alphas = [500, 750, 1000, 1250, 1500]\n",
    "\n",
    "\n",
    "def unflatten_mvmd_data(u, u_hat, subjects, regions=232):\n",
    "    assert int(u.shape[1]//regions) == len(subjects), f\"The number of subjects does not match the number of rows in u. Got {int(u.shape[1]//regions)} subjects and {len(subjects)} rows.\"\n",
    "    data = [\n",
    "        (\n",
    "            u[:, i * regions:(i + 1) * regions, :],\n",
    "            u_hat[:, i * regions:(i + 1) * regions, :]\n",
    "        )\n",
    "        for i in range(len(subjects))\n",
    "    ]\n",
    "    return dict(zip(subjects, data))\n",
    "\n",
    "def run_experiment_K(data_df, sample_rate, run_no, Ks, results_folder, alpha = 1000, tol = 1e-7, column = 'scans'):\n",
    "    filtered_df = data_df[(data_df['sample_rate'] == sample_rate) & (data_df['run'] == run_no)].reset_index(drop=True)\n",
    "    assert len(filtered_df) == 1, \"More than one subject found for the given sample rate and run number.\"\n",
    "    for K in tqdm(Ks):\n",
    "        folder_name = f'{results_folder}/K_{K}'\n",
    "\n",
    "        os.makedirs(folder_name, exist_ok=True)\n",
    "        u, u_hat, omega = mvmd(filtered_df[column].values[0], num_modes=K, alpha=alpha, tolerance=tol, freq=filtered_df['sample_rate'].values[0])\n",
    "        unflattened = unflatten_mvmd_data(u, u_hat, filtered_df['subjects'].values[0])\n",
    "        for subject, (u_data, u_hat_data) in unflattened.items():\n",
    "            assert u_data.shape == (K, 232, filtered_df['timepoints'].values[0]), f\"u_data shape mismatch for subject {subject}. Expected {filtered_df['timepoints'].values[0]}, got {u_data.shape[0]}\"\n",
    "            sio.savemat(os.path.join(folder_name, f'{subject}_{u_data.shape[-1]}.mat'), {'u': u_data, \"u_hat\": u_hat_data, \"omega\": omega})\n",
    "           \n",
    "def run_experiment_alpha(data_df, sample_rate, run_no, alphas, results_folder, K = 10, tol = 1e-7, column = 'scans'):\n",
    "    filtered_df = data_df[(data_df['sample_rate'] == sample_rate) & (data_df['run'] == run_no)].reset_index(drop=True)\n",
    "    assert len(filtered_df) == 1, \"More than one subject found for the given sample rate and run number.\"\n",
    "    for alpha in tqdm(alphas):\n",
    "        folder_name = f'{results_folder}/alpha_{alpha}'\n",
    "\n",
    "        os.makedirs(folder_name, exist_ok=True)\n",
    "        u, u_hat, omega = mvmd(filtered_df[column].values[0], num_modes=K, alpha=alpha, tolerance=tol, freq=filtered_df['sample_rate'].values[0])\n",
    "        unflattened = unflatten_mvmd_data(u, u_hat, filtered_df['subjects'].values[0])\n",
    "        for subject, (u_data, u_hat_data) in unflattened.items():\n",
    "            assert u_data.shape == (K, 232, filtered_df['timepoints'].values[0]), f\"u_data shape mismatch for subject {subject}. Expected {filtered_df['timepoints'].values[0]}, got {u_data.shape[0]}\"\n",
    "            sio.savemat(os.path.join(folder_name, f'{subject}_{u_data.shape[-1]}.mat'), {'u': u_data, \"u_hat\": u_hat_data, \"omega\": omega}) \n",
    "\n",
    "def groupruns(data_df, timepoints=375, sr = 0.8, datacolumn = 'scans_0mean'):\n",
    "    grouped_runs = []\n",
    "    # Loop through each run\n",
    "    for run, run_data in data_df.groupby('run'):\n",
    "        stacked_data = []\n",
    "        stacked_data_detrended = []\n",
    "        subjects = []  # List to store subject identifiers for this run\n",
    "        filenames = []\n",
    "        stacked_data_detrended_2nd = []\n",
    "        \n",
    "        # For each subject in the run, flatten the 232x300 matrix into 232 rows and collect them\n",
    "        for _, row in run_data.iterrows():\n",
    "            # Extract the 232x300 matrix for the subject\n",
    "            scans_matrix = row[datacolumn]\n",
    "                        \n",
    "            stacked_data.append(scans_matrix)  # Append the matrix as-is (shape will be (232, 300))\n",
    "            subjects.append(row['subject'])  # Append the subject to the list\n",
    "            filenames.append(row['filename'])\n",
    "\n",
    "        flattened_data = np.vstack(stacked_data)  \n",
    "        grouped_runs.append([subjects, filenames, sr, timepoints, run, flattened_data])\n",
    "    return grouped_runs\n",
    "\n",
    "def run_experiment_K_single(data_df, sample_rate, run_no, Ks, results_folder, alpha = 1000, tol = 1e-7, column = 'scans'):\n",
    "    filtered_df = data_df[(data_df['sample_rate'] == sample_rate) & (data_df['run'] == run_no)].reset_index(drop=True)\n",
    "    for K in tqdm(Ks):\n",
    "        folder_name = f'{results_folder}/K_{K}'\n",
    "\n",
    "        os.makedirs(folder_name, exist_ok=True)\n",
    "        for _, row in filtered_df.iterrows():\n",
    "            subject = row['subject']\n",
    "            timepoints = row['timepoints']\n",
    "            u, u_hat, omega = mvmd(row[column], num_modes=K, alpha=alpha, tolerance=tol, freq=filtered_df['sample_rate'].values[0])\n",
    "            sio.savemat(os.path.join(folder_name, f'{subject}_{timepoints}.mat'), {'u': u, \"u_hat\": u_hat, \"omega\": omega})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some final signle experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [04:03<00:00, 243.52s/it]\n",
      "100%|██████████| 1/1 [03:30<00:00, 210.81s/it]\n",
      "100%|██████████| 1/1 [04:19<00:00, 259.48s/it]\n",
      "100%|██████████| 1/1 [04:25<00:00, 265.46s/it]\n",
      "100%|██████████| 1/1 [03:11<00:00, 191.71s/it]\n",
      "100%|██████████| 1/1 [00:24<00:00, 24.43s/it]\n",
      "100%|██████████| 1/1 [00:24<00:00, 24.69s/it]\n",
      "100%|██████████| 1/1 [00:10<00:00, 10.59s/it]\n"
     ]
    }
   ],
   "source": [
    "data_df_300 = data_df[data_df['sample_rate'] == 2]\n",
    "\n",
    "for run in range(len(data_df_300.run.unique())):\n",
    "    run_experiment_K_single(data_df_300, 2.0, run, [6], f'Run1005/Results_0mean/Results_run-{run}_2000ms_/', column='scans_0mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [03:45<00:00, 225.16s/it]\n",
      "100%|██████████| 1/1 [04:43<00:00, 283.55s/it]\n",
      "100%|██████████| 1/1 [07:02<00:00, 422.78s/it]\n",
      "100%|██████████| 1/1 [05:31<00:00, 331.57s/it]\n",
      "100%|██████████| 1/1 [04:44<00:00, 284.81s/it]\n",
      "100%|██████████| 1/1 [10:59<00:00, 659.03s/it]\n",
      "100%|██████████| 1/1 [05:56<00:00, 356.87s/it]\n",
      "100%|██████████| 1/1 [07:28<00:00, 448.19s/it]\n",
      "100%|██████████| 1/1 [09:48<00:00, 588.81s/it]\n",
      "100%|██████████| 1/1 [06:30<00:00, 390.58s/it]\n"
     ]
    }
   ],
   "source": [
    "data_df_375 = data_df[data_df['timepoints'] == 375] \n",
    "data_df_750 = data_df[data_df['timepoints'] == 750] \n",
    "\n",
    "\n",
    "for run in range(len(data_df_375.run.unique())):\n",
    "    run_experiment_K_single(data_df_375, 0.8, run, [10], f'Run1005/Results_0mean/Results_run-{run}_800ms_/', column='scans_0mean')\n",
    "\n",
    "for run in range(len(data_df_750.run.unique())):\n",
    "    run_experiment_K_single(data_df_750, 0.8, run, [10], f'Run1005/Results_0mean/Results_run-{run}_800ms_/', column='scans_0mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 200 ms experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df_300 = data_df[data_df['sample_rate'] == 2]\n",
    "data_df_300 = data_df_300[data_df_300['timepoints'] == 300]\n",
    "\n",
    "\n",
    "grouped_runs_300 = groupruns(data_df_300, timepoints = 300, sr = 2.0, datacolumn='scans_0mean')\n",
    "\n",
    "final_df_300 = pd.DataFrame(grouped_runs_300, columns=['subjects', 'filenames', 'sample_rate', 'timepoints', 'run', 'scans_0mean'])\n",
    "#final_df_300 = pd.DataFrame(grouped_runs_300, columns=['subjects', 'filenames', 'sample_rate', 'timepoints', 'run', 'scans'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [38:21<00:00, 383.55s/it]\n"
     ]
    }
   ],
   "source": [
    "run_experiment_K(final_df_300, 2.0, 0, [4,5,7,8,9,10], f'Run0605/Results_0mean/Results_run-{0}_2000ms_/', column='scans_0mean')\n",
    "\n",
    "#for run in range(len(final_df_300)):\n",
    "#    run_experiment_K(final_df_300, 2.0, run, [6], f'Run0605/Results_0mean/Results_run-{run}_2000ms_/', column='scans_0mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 800 ms experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1st way, do it seperately for 375 and 750 timepoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df_375 = data_df[data_df['timepoints'] == 375] \n",
    "data_df_750 = data_df[data_df['timepoints'] == 750]\n",
    "\n",
    "grouped_runs_375 = groupruns(data_df_375, 375, datacolumn='scans_0mean')\n",
    "grouped_runs_750 = groupruns(data_df_750, 750, datacolumn='scans_0mean')\n",
    "\n",
    "final_df_375 = pd.DataFrame(grouped_runs_375, columns=['subjects', 'filenames', 'sample_rate', 'timepoints', 'run', 'scans_0mean'])\n",
    "final_df_750 = pd.DataFrame(grouped_runs_750, columns=['subjects', 'filenames', 'sample_rate', 'timepoints', 'run', 'scans_0mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [06:53<00:00, 413.96s/it]\n",
      "100%|██████████| 1/1 [05:49<00:00, 349.02s/it]\n",
      "100%|██████████| 1/1 [06:23<00:00, 383.94s/it]\n",
      "100%|██████████| 1/1 [04:47<00:00, 287.11s/it]\n",
      "100%|██████████| 1/1 [04:28<00:00, 268.12s/it]\n",
      "100%|██████████| 1/1 [10:09<00:00, 609.05s/it]\n",
      "100%|██████████| 1/1 [06:12<00:00, 372.69s/it]\n",
      "100%|██████████| 1/1 [07:55<00:00, 475.77s/it]\n",
      "100%|██████████| 1/1 [07:43<00:00, 463.85s/it]\n",
      "100%|██████████| 1/1 [08:00<00:00, 480.73s/it]\n"
     ]
    }
   ],
   "source": [
    "for run in range(len(final_df_375)):\n",
    "    run_experiment_K(final_df_375, 0.8, run, [10], f'Run0605/Results_0mean/Results_run-{run}_800ms_/', column='scans_0mean')\n",
    "\n",
    "for run in range(len(final_df_750)):\n",
    "    run_experiment_K(final_df_750, 0.8, run, [10], f'Run0605/Results_0mean/Results_run-{run}_800ms_/', column='scans_0mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "More than one subject found for the given sample rate and run number.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mrun_experiment_K\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfinal_df_375\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m9\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m11\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m12\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m13\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mRun0605/Results_0mean/Results_run-\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;241;43m0\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_800ms_/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mscans_0mean\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m run_experiment_K(final_df_750, \u001b[38;5;241m2.0\u001b[39m, \u001b[38;5;241m0\u001b[39m, [\u001b[38;5;241m9\u001b[39m,\u001b[38;5;241m10\u001b[39m,\u001b[38;5;241m11\u001b[39m,\u001b[38;5;241m12\u001b[39m,\u001b[38;5;241m13\u001b[39m], \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRun0605/Results_0mean/Results_run-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;241m0\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_800ms_/\u001b[39m\u001b[38;5;124m'\u001b[39m, column\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscans_0mean\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[3], line 23\u001b[0m, in \u001b[0;36mrun_experiment_K\u001b[0;34m(data_df, sample_rate, run_no, Ks, results_folder, alpha, tol, column)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_experiment_K\u001b[39m(data_df, sample_rate, run_no, Ks, results_folder, alpha \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m, tol \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1e-7\u001b[39m, column \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscans\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     22\u001b[0m     filtered_df \u001b[38;5;241m=\u001b[39m data_df[(data_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msample_rate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m sample_rate) \u001b[38;5;241m&\u001b[39m (data_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrun\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m run_no)]\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 23\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(filtered_df) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMore than one subject found for the given sample rate and run number.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m K \u001b[38;5;129;01min\u001b[39;00m tqdm(Ks):\n\u001b[1;32m     25\u001b[0m         folder_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresults_folder\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/K_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mK\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: More than one subject found for the given sample rate and run number."
     ]
    }
   ],
   "source": [
    "run_experiment_K(final_df_375, 2.0, 0, [9,10,11,12,13], f'Run0605/Results_0mean/Results_run-{0}_800ms_/', column='scans_0mean')\n",
    "run_experiment_K(final_df_750, 2.0, 0, [9,10,11,12,13], f'Run0605/Results_0mean/Results_run-{0}_800ms_/', column='scans_0mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [06:23<00:00, 383.80s/it]\n",
      "100%|██████████| 1/1 [06:05<00:00, 365.60s/it]\n",
      "100%|██████████| 1/1 [06:04<00:00, 364.53s/it]\n",
      "100%|██████████| 1/1 [05:13<00:00, 313.44s/it]\n",
      "100%|██████████| 1/1 [05:08<00:00, 308.74s/it]\n",
      "100%|██████████| 1/1 [12:22<00:00, 742.25s/it]\n",
      "100%|██████████| 1/1 [07:22<00:00, 442.90s/it]\n",
      "100%|██████████| 1/1 [13:10<00:00, 790.53s/it]\n",
      "100%|██████████| 1/1 [12:21<00:00, 741.09s/it]\n",
      "100%|██████████| 1/1 [07:15<00:00, 435.44s/it]\n"
     ]
    }
   ],
   "source": [
    "run_experiment_K(final_df_375, 0.8, 1, [10], 'Run0505/Results_detrended/Results_run-0_800ms_/', column='scans_0mean')\n",
    "run_experiment_K(final_df_375, 0.8, 2, [10], 'Run0505/Results_detrended/Results_run-1_800ms_/', column='scans_0mean')\n",
    "run_experiment_K(final_df_375, 0.8, 3, [10], 'Run0505/Results_detrended/Results_run-2_800ms_/', column='scans_0mean')\n",
    "run_experiment_K(final_df_375, 0.8, 4, [10], 'Run0505/Results_detrended/Results_run-3_800ms_/', column='scans_0mean')\n",
    "run_experiment_K(final_df_375, 0.8, 5, [10], 'Run0505/Results_detrended/Results_run-4_800ms_/', column='scans_0mean')\n",
    "\n",
    "run_experiment_K(final_df_750, 0.8, 1, [10], 'Run0505/Results_detrended/Results_run-0_800ms_/', column='scans_0mean')\n",
    "run_experiment_K(final_df_750, 0.8, 2, [10], 'Run0505/Results_detrended/Results_run-1_800ms_/', column='scans_0mean')\n",
    "run_experiment_K(final_df_750, 0.8, 3, [10], 'Run0505/Results_detrended/Results_run-2_800ms_/', column='scans_0mean')\n",
    "run_experiment_K(final_df_750, 0.8, 4, [10], 'Run0505/Results_detrended/Results_run-3_800ms_/', column='scans_0mean')\n",
    "run_experiment_K(final_df_750, 0.8, 5, [10], 'Run0505/Results_detrended/Results_run-4_800ms_/', column='scans_0mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [27:00<00:00, 270.13s/it]\n",
      "100%|██████████| 6/6 [42:49<00:00, 428.29s/it]\n",
      "100%|██████████| 6/6 [30:03<00:00, 300.51s/it]\n",
      "100%|██████████| 6/6 [38:25<00:00, 384.18s/it]\n",
      "100%|██████████| 6/6 [29:22<00:00, 293.70s/it]\n",
      "100%|██████████| 6/6 [45:51<00:00, 458.58s/it]\n",
      "100%|██████████| 6/6 [25:19<00:00, 253.22s/it]\n",
      "100%|██████████| 6/6 [43:09<00:00, 431.52s/it]\n",
      "100%|██████████| 6/6 [25:02<00:00, 250.39s/it]\n",
      "100%|██████████| 6/6 [43:09<00:00, 431.55s/it]\n"
     ]
    }
   ],
   "source": [
    "run_experiment_alpha(final_df_375, 0.8, 1, [1250, 1500, 2000, 2500, 3000, 5000], 'Run2304/Results_0mean/Results_run-0_800ms_/', column='scans_0mean')\n",
    "run_experiment_alpha(final_df_750, 0.8, 1, [1250, 1500, 2000, 2500, 3000, 5000], 'Run2304/Results_0mean/Results_run-0_800ms_/', column='scans_0mean')\n",
    "\n",
    "run_experiment_alpha(final_df_375, 0.8, 2, [1250, 1500, 2000, 2500, 3000, 5000], 'Run2304/Results_0mean/Results_run-1_800ms_/', column='scans_0mean')\n",
    "run_experiment_alpha(final_df_750, 0.8, 2, [1250, 1500, 2000, 2500, 3000, 5000], 'Run2304/Results_0mean/Results_run-1_800ms_/', column='scans_0mean')\n",
    "\n",
    "run_experiment_alpha(final_df_375, 0.8, 3, [1250, 1500, 2000, 2500, 3000, 5000], 'Run2304/Results_0mean/Results_run-2_800ms_/', column='scans_0mean')\n",
    "run_experiment_alpha(final_df_750, 0.8, 3, [1250, 1500, 2000, 2500, 3000, 5000], 'Run2304/Results_0mean/Results_run-2_800ms_/', column='scans_0mean')\n",
    "\n",
    "run_experiment_alpha(final_df_375, 0.8, 4, [1250, 1500, 2000, 2500, 3000, 5000], 'Run2304/Results_0mean/Results_run-3_800ms_/', column='scans_0mean')\n",
    "run_experiment_alpha(final_df_750, 0.8, 4, [1250, 1500, 2000, 2500, 3000, 5000], 'Run2304/Results_0mean/Results_run-3_800ms_/', column='scans_0mean')\n",
    "\n",
    "run_experiment_alpha(final_df_375, 0.8, 5, [1250, 1500, 2000, 2500, 3000, 5000], 'Run2304/Results_0mean/Results_run-4_800ms_/', column='scans_0mean')\n",
    "run_experiment_alpha(final_df_750, 0.8, 5, [1250, 1500, 2000, 2500, 3000, 5000], 'Run2304/Results_0mean/Results_run-4_800ms_/', column='scans_0mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [43:37<00:00, 373.94s/it]\n",
      "100%|██████████| 7/7 [34:10<00:00, 292.98s/it]\n",
      "100%|██████████| 7/7 [45:07<00:00, 386.83s/it]\n",
      "100%|██████████| 7/7 [46:14<00:00, 396.34s/it]\n",
      "100%|██████████| 7/7 [43:32<00:00, 373.25s/it]\n"
     ]
    }
   ],
   "source": [
    "run_experiment_K(final_df_750, 0.8, 1, range(6, 13), 'Run2304/Results_0mean/Results_run-0_800ms_/', column='scans_0mean')\n",
    "run_experiment_K(final_df_750, 0.8, 2, range(6, 13), 'Run2304/Results_0mean/Results_run-1_800ms_/', column='scans_0mean')\n",
    "run_experiment_K(final_df_750, 0.8, 3, range(6, 13), 'Run2304/Results_0mean/Results_run-2_800ms_/', column='scans_0mean')\n",
    "run_experiment_K(final_df_750, 0.8, 4, range(6, 13), 'Run2304/Results_0mean/Results_run-3_800ms_/', column='scans_0mean')\n",
    "run_experiment_K(final_df_750, 0.8, 5, range(6, 13), 'Run2304/Results_0mean/Results_run-4_800ms_/', column='scans_0mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [27:39<00:00, 237.10s/it]\n"
     ]
    }
   ],
   "source": [
    "run_experiment_K(final_df_375, 0.8, 5, range(6, 13), 'Run2304/Results_0mean/Results_run-4_800ms_/', column='scans_0mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mvmd_data = pickle.load(open('DATA/mvmd_data.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "participant                                               sub-55162\n",
       "filepath          Run1903/Results_0mean/Results_run-0_800ms_/K_1...\n",
       "num_timepoints                                                  375\n",
       "run                                                               0\n",
       "sample_rate                                                     0.8\n",
       "u                 [[[-7.684070557813361, -7.609754178828222, -7....\n",
       "K                                                                10\n",
       "u_hat             [[[(1.0997298085039044e-10+0j), (2.69045825015...\n",
       "omegas            [0.011300291801789762, 0.02701443722876842, 0....\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mvmd_data.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 33797.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run2304/Results_0mean/Results_run-0_2000ms_/K_5\n",
      "Run2304/Results_0mean/Results_run-0_800ms_/K_10\n",
      "Run2304/Results_0mean/Results_run-1_2000ms_/K_5\n",
      "Run2304/Results_0mean/Results_run-1_800ms_/K_10\n",
      "Run2304/Results_0mean/Results_run-2_2000ms_/K_5\n",
      "Run2304/Results_0mean/Results_run-2_800ms_/K_10\n",
      "Run2304/Results_0mean/Results_run-3_800ms_/K_10\n",
      "Run2304/Results_0mean/Results_run-3_2000ms_/K_5\n",
      "Run2304/Results_0mean/Results_run-4_800ms_/K_10\n",
      "Run2304/Results_0mean/Results_run-4_2000ms_/K_5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "subdirectories = os.listdir(base_folder)\n",
    "for subdir in tqdm(subdirectories):\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:06<00:00,  1.52it/s]\n"
     ]
    }
   ],
   "source": [
    "# Directories to pickle file\n",
    "subdir_path = ''\n",
    "long_data = []\n",
    "base_folder = 'Run2304/Results_0mean'\n",
    "\n",
    "\n",
    "subdirectories = os.listdir(base_folder)\n",
    "for subdir in tqdm(subdirectories):\n",
    "    sr = float(subdir.split('_')[2].split('ms')[0]) / 1000\n",
    "    subdir_path = ''\n",
    "    if sr == 0.8:\n",
    "        subdir_path = os.path.join(base_folder,subdir, 'K_10')\n",
    "    else:\n",
    "        subdir_path = os.path.join(base_folder, subdir, 'K_5')\n",
    "\n",
    "\n",
    "    if os.path.isdir(subdir_path):\n",
    "        mat_files = [f for f in os.listdir(subdir_path) if f.endswith('.mat')]\n",
    "        for mat_file in mat_files:\n",
    "            file_path = os.path.join(subdir_path, mat_file)\n",
    "            data = loadmat(file_path)\n",
    "        \n",
    "            long_data.append({\n",
    "                'participant': mat_file.split('_')[0],\n",
    "                'filepath': file_path,\n",
    "                'num_timepoints': mat_file.split('_')[1].split('.')[0],\n",
    "                'u': data['u'],\n",
    "                'u_hat': data['u_hat'],\n",
    "                'omega': data['omega'],\n",
    "                'sample_rate': float(subdir.split('_')[2].split('ms')[0]) / 1000,\n",
    "                'run': int(subdir.split('_')[1].split('-')[1]),\n",
    "            }\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['300', '375', '750'], dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mvmd_data_combined.num_timepoints.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "mvmd_data_combined = pd.DataFrame(long_data)\n",
    "mvmd_data_combined\n",
    "pickle.dump(mvmd_data_combined, open('DATA/mvmd_data_concatenated.pkl', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
